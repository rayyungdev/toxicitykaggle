{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35203a5e",
   "metadata": {},
   "source": [
    "# Ranking Toxic Comments using LSTM network maybe?\n",
    "\n",
    "So while ray is trying the more efficient approach of using naive-bayes classification, I'd try training an entire LSTM to solve this problem... in jupyter notebook... so uh.. yeah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "276b2cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, GRU, Dense, Dropout\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d067aff7",
   "metadata": {},
   "source": [
    "My plan is to use two LSTM networks, to encode both comments and output a one-hot vector with 2 values, one for if it's greater and one for if it's less. Given that the dataset only identifies if one is greater than the other, we can only make determinations based on that, so the network reflects that\n",
    "\n",
    "Something like this:\n",
    "\n",
    "![Toxicity LSTM Network](toxicity-lstm-network.svg)\n",
    "\n",
    "I think the size of each layer can be determined by some hyperparameter tuning (or just guess & check since I'm not google and don't have infinite compute power)\n",
    "\n",
    "But first we need to download and extract the data. This requires `unzip` if you're on mac/linux, and `7z` if you're on Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9009b338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "%%bash\n",
    "# Download and extract data (run if on Linux/MacOS)\n",
    "rm -rf data\n",
    "mkdir data\n",
    "cd data\n",
    "kaggle competitions download --force -c jigsaw-toxic-severity-rating\n",
    "unzip jigsaw-toxic-severity-rating.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa12dd31-8730-4827-97fe-411a057cc90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.19043.1415]\n",
      "(c) Microsoft Corporation. All rights reserved.\n",
      "\n",
      "(env) C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle>rmdir /S/Q data\n",
      "\n",
      "(env) C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle>mkdir data\n",
      "\n",
      "(env) C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle>cd data\n",
      "\n",
      "(env) C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\data>kaggle competitions download --force -c jigsaw-toxic-severity-rating\n",
      "Downloading jigsaw-toxic-severity-rating.zip to C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 6.72M/6.72M [00:00<00:00, 17.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "(env) C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\data>7z.exe x jigsaw-toxic-severity-rating.zip\n",
      "\n",
      "7-Zip 19.00 (x64) : Copyright (c) 1999-2018 Igor Pavlov : 2019-02-21\n",
      "\n",
      "Scanning the drive for archives:\n",
      "1 file, 7041334 bytes (6877 KiB)\n",
      "\n",
      "Extracting archive: jigsaw-toxic-severity-rating.zip\n",
      "--\n",
      "Path = jigsaw-toxic-severity-rating.zip\n",
      "Type = zip\n",
      "Physical Size = 7041334\n",
      "\n",
      "Everything is Ok\n",
      "\n",
      "Files: 3\n",
      "Size:       28845412\n",
      "Compressed: 7041334\n",
      "\n",
      "(env) C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\data>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "rmdir /S/Q data\n",
    "mkdir data\n",
    "cd data\n",
    "kaggle competitions download --force -c jigsaw-toxic-severity-rating\n",
    "7z.exe x jigsaw-toxic-severity-rating.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47edf9f",
   "metadata": {},
   "source": [
    "Now that we have our data, we can create a function to pull it and convert it into a tensorflow dataset for our model. The worker is the id of the person that scored the comments. They're not really important so we can ignore that column. So for each row, we'll need the row as is and also the reverse of the row (a,b and b,a). This way we can train the model to understand both greater than and less than cases. Otherwise all of these outputs will be just 1. Then we need to encode our comments into a form our network can understand. We can do this using `tf.keras.layers.TextVectorization`. This will learn the best way to encode our characters by analyzing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18583bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling data...\n",
      "Generating labeled data...\n",
      "Encoding inputs...\n",
      "Vocab size: 97647\n",
      "Encoding labels...\n",
      "Creating dataset...\n",
      "Dataset spec: <RepeatDataset shapes: (((None, None), (None, None)), (None, 2)), types: ((tf.int64, tf.int64), tf.float64)>\n",
      "Sample input sequence A: tf.Tensor([  417   167  6872  2993  7660 43622], shape=(6,), dtype=int64)\n",
      "Sample input sequence B: tf.Tensor(\n",
      "[ 3299 83209  1469    28    28    15    40 19753     5  3634    39   264\n",
      "    30     4  7004    32   638    24   462  1847   272    45     2 82892\n",
      "    98   190    28 27332   395    61  1069     8     2   187     3    20\n",
      "    29     2  3299 83210    39    64     8  4503  2669   832    16     4\n",
      "  2329 91941], shape=(50,), dtype=int64)\n",
      "Sample output labels: tf.Tensor([0. 1.], shape=(2,), dtype=float64)\n",
      "Splitting into training and testing...\n",
      "All done :-)\n"
     ]
    }
   ],
   "source": [
    "def input_data(train_frac=0.7, shuffle=200, batch=200, repeat=3, display=False):\n",
    "    \"\"\"\n",
    "    Extract and preprocess data for trainer\n",
    "    \n",
    "    :param shuffle: size of groups to shuffle rows in\n",
    "    :param batch: size of batches to segment data into\n",
    "    :param repeat: number of times to repeat dataset\n",
    "    :param display: if true, print a sample of data\n",
    "    \"\"\"\n",
    "    # Pull data from csv\n",
    "    print('Pulling data...')\n",
    "    csv_data = pd.read_csv('data/validation_data.csv')\n",
    "    csv_data = csv_data[['less_toxic', 'more_toxic']]\n",
    "    \n",
    "    # Our inputs are labeled as \"more toxic\" and \"less toxic\"\n",
    "    # but we want to pass in both with their comparision being\n",
    "    # unknown, as the network is supposed to figure that out.\n",
    "    # So, we create two sets, one of which has the order swapped\n",
    "    # and we name both sequence columns as \"sequence A\" and \n",
    "    # \"sequence B\" We then assign a label to each, with the \n",
    "    # original having 'greater' and the swapped one having 'less'. \n",
    "    # Therefore, the network will see both cases for each input \n",
    "    # in the dataset and can train for both\n",
    "    print('Generating labeled data...')\n",
    "    labeled_data_greater = csv_data.copy()\n",
    "    labeled_data_greater.rename(\n",
    "        columns={'less_toxic': 'seq_a', 'more_toxic': 'seq_b' }, \n",
    "        inplace=True)\n",
    "    labeled_data_greater['label'] = 'greater'\n",
    "    labeled_data_less = csv_data.copy()\n",
    "    labeled_data_less.rename(\n",
    "        columns={ 'more_toxic': 'seq_a', 'less_toxic': 'seq_b' }, \n",
    "        inplace=True)\n",
    "    labeled_data_less['label'] = 'less'\n",
    "    labeled_data = pd.concat([ labeled_data_greater, labeled_data_less ])\n",
    "    labeled_data = labeled_data.sample(frac=1)\n",
    "    \n",
    "    # Now we take all sequences of characters and convert them to sequences \n",
    "    # of integers. We can do that using keras's TextVectorization preprocessing \n",
    "    # layer, which will take a string and spit out an array of integers \n",
    "    # encoding the woprds of the string. This layer will need to scan \n",
    "    # the dataset to determine the appropriate encoding vocabulary for the \n",
    "    # characters. Since both sequences essentially contain all of the data, \n",
    "    # we can just use one of the sequences for the TextVectorization to scan.\n",
    "    print('Encoding inputs...')\n",
    "    seq_a = tf.constant(labeled_data['seq_a'].values.reshape(-1,1))\n",
    "    seq_b = tf.constant(labeled_data['seq_b'].values.reshape(-1,1))\n",
    "    encoder = tf.keras.layers.TextVectorization(\n",
    "        standardize=None,\n",
    "        ragged=True)\n",
    "    encoder.adapt(seq_a)\n",
    "    vocab_size = encoder.vocabulary_size()\n",
    "    if display:\n",
    "        print('Vocab size:', vocab_size)\n",
    "    seqint_a = encoder(seq_a)\n",
    "    seqint_b = encoder(seq_b)\n",
    "    \n",
    "    # Then we can one-hot encode our labels using scikit-learn's \n",
    "    # OneHotEncoder class. Since we know our labels ahead of time, \n",
    "    # I figured we don't need to train it. HOWEVER, scikit-learn \n",
    "    # doesn't seem to think so, as it expects us to call fit on \n",
    "    # the data anyway... so yeah.\n",
    "    print('Encoding labels...')\n",
    "    label_encoder = OneHotEncoder(\n",
    "        categories=[['greater', 'less']], \n",
    "        handle_unknown='ignore')\n",
    "    label_array = labeled_data['label'].values.reshape(-1, 1)\n",
    "    label_encoder.fit(label_array)\n",
    "    labels = label_encoder.transform(label_array)\n",
    "    labels = tf.constant(labels.toarray())\n",
    "    \n",
    "    # Create dataset. Shuffle, batch, repeat, etc.\n",
    "    print('Creating dataset...')\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        ((seqint_a, seqint_b), labels))\n",
    "    dataset = dataset.shuffle(shuffle)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.repeat(repeat)\n",
    "    \n",
    "    # Display a sample\n",
    "    if display:\n",
    "        print('Dataset spec:', dataset)\n",
    "        for (seq_a, seq_b), output in dataset.take(1):\n",
    "            print(f'Sample input sequence A:', seq_a[0])\n",
    "            print(f'Sample input sequence B:', seq_b[0])\n",
    "            print(f'Sample output labels:', output[0])\n",
    "            \n",
    "    # Split into training and testing data\n",
    "    print('Splitting into training and testing...')\n",
    "    train_num = int(train_frac*len(dataset))\n",
    "    train_dataset = dataset.take(train_num)\n",
    "    test_dataset = dataset.skip(train_num)\n",
    "    \n",
    "    # Return training data, testing data, and vocab size\n",
    "    print('All done :-)')\n",
    "    return train_dataset, test_dataset, vocab_size\n",
    "    \n",
    "# Run input data function to test it out\n",
    "train_dataset, test_dataset, vocab_size = input_data(display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c30a7a",
   "metadata": {},
   "source": [
    "After this. We build the model using Keras's framework, train it and then validate it on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4b5252",
   "metadata": {},
   "source": [
    "The original problem calls for ranking comments based on toxicity, so we can use this network as a comparator function to sort the list of toxic comments. So, first, the network. I'm creating a function which would return a model based on parameters. This will be used for the optimization step.\n",
    "\n",
    "In the last minute, I decided that, instead of an LSTM network, I would be using a GRU network.\n",
    "\n",
    "If you don't like that decision I will stuff you in the crust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b1ab5d8-fb8d-4677-941b-d67f97cbe93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_a (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_b (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embed_a (Embedding)            (None, None, 128)    12498816    ['input_a[0][0]']                \n",
      "                                                                                                  \n",
      " embed_b (Embedding)            (None, None, 128)    12498816    ['input_b[0][0]']                \n",
      "                                                                                                  \n",
      " recur_a (GRU)                  (None, 64)           37248       ['embed_a[0][0]']                \n",
      "                                                                                                  \n",
      " recur_b (GRU)                  (None, 64)           37248       ['embed_b[0][0]']                \n",
      "                                                                                                  \n",
      " drop_a (Dropout)               (None, 64)           0           ['recur_a[0][0]']                \n",
      "                                                                                                  \n",
      " drop_b (Dropout)               (None, 64)           0           ['recur_b[0][0]']                \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 128)          0           ['drop_a[0][0]',                 \n",
      "                                                                  'drop_b[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           8256        ['tf.concat[0][0]']              \n",
      "                                                                                                  \n",
      " drop_d (Dropout)               (None, 64)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " labels (Dense)                 (None, 2)            130         ['drop_d[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25,080,514\n",
      "Trainable params: 25,080,514\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(vocab_size, embed_units=128, recur_units=64, dense_units=64, dropout_rate=0.1):\n",
    "    \"\"\"\n",
    "    Create model using parameters\n",
    "    \"\"\"\n",
    "    # A LSTM network\n",
    "    input_a = Input((None,), name='input_a')\n",
    "    embed_a = Embedding(vocab_size, embed_units, name='embed_a')(input_a)\n",
    "    recur_a = GRU(recur_units, name='recur_a')(embed_a)\n",
    "    drop_a = Dropout(dropout_rate, name='drop_a')(recur_a)\n",
    "    \n",
    "    # B LSTM network\n",
    "    input_b = Input((None,), name='input_b')\n",
    "    embed_b = Embedding(vocab_size, embed_units, name='embed_b')(input_b)\n",
    "    recur_b = GRU(recur_units, name='recur_b')(embed_b)\n",
    "    drop_b = Dropout(dropout_rate, name='drop_b')(recur_b)\n",
    "    \n",
    "    # Concatenation and dense layers\n",
    "    concat = tf.concat([ drop_a, drop_b ], axis=1, name='concatenate')\n",
    "    dense = Dense(dense_units, activation='relu', name='dense')(concat)\n",
    "    drop_d = Dropout(dropout_rate, name='drop_d')(dense)\n",
    "    output = Dense(2, activation='softmax', name='labels')(drop_d) # 2 labels in the output layer\n",
    "    \n",
    "    # Final model configuration\n",
    "    model = Model([input_a, input_b], output)\n",
    "    model.summary()\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=CategoricalCrossentropy(),\n",
    "        metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Horay model created\n",
    "tf.keras.backend.clear_session()\n",
    "model = create_model(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b16b7d-7dca-4a6a-afc3-e60f97a49b6b",
   "metadata": {},
   "source": [
    "Now we fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4944555a-7caf-46e4-bfe4-408bf002d98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/recur_a/RaggedToTensor/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/recur_a/RaggedToTensor/boolean_mask/GatherV2:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/recur_a/RaggedToTensor/Shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/recur_b/RaggedToTensor/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/recur_b/RaggedToTensor/boolean_mask/GatherV2:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/recur_b/RaggedToTensor/Shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31/634 [>.............................] - ETA: 1:59:13 - loss: 0.6892 - accuracy: 0.5410"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[200,1000,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/model/recur_a/transpose/transpose\n (defined at C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:464)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[gradient_tape/model/recur_a/RaggedToTensor/strided_slice/_180]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[200,1000,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/model/recur_a/transpose/transpose\n (defined at C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:464)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_9422]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/model/recur_a/transpose/transpose:\nIn[0] gradient_tape/model/recur_a/TensorArrayUnstack/TensorListStack:\t\nIn[1] gradient_tape/model/recur_a/transpose/InvertPermutation:\n\nOperation defined at: (most recent call last)\n>>>   File \"c:\\program files\\python38\\lib\\runpy.py\", line 193, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"c:\\program files\\python38\\lib\\runpy.py\", line 86, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"c:\\program files\\python38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"c:\\program files\\python38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"c:\\program files\\python38\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 461, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 450, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 652, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n>>>     if await self.run_code(code, result, async_=asy):\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\AppData\\Local\\Temp\\ipykernel_10760\\1211049778.py\", line 1, in <module>\n>>>     model.fit(train_dataset, epochs=1)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 816, in train_step\n>>>     self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 530, in minimize\n>>>     grads_and_vars = self._compute_gradients(\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 583, in _compute_gradients\n>>>     grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 464, in _get_gradients\n>>>     grads = tape.gradient(loss, var_list, grad_loss)\n>>> \n\nInput Source operations connected to node gradient_tape/model/recur_a/transpose/transpose:\nIn[0] gradient_tape/model/recur_a/TensorArrayUnstack/TensorListStack:\t\nIn[1] gradient_tape/model/recur_a/transpose/InvertPermutation:\n\nOperation defined at: (most recent call last)\n>>>   File \"c:\\program files\\python38\\lib\\runpy.py\", line 193, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"c:\\program files\\python38\\lib\\runpy.py\", line 86, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"c:\\program files\\python38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"c:\\program files\\python38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"c:\\program files\\python38\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 461, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 450, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 652, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n>>>     if await self.run_code(code, result, async_=asy):\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\AppData\\Local\\Temp\\ipykernel_10760\\1211049778.py\", line 1, in <module>\n>>>     model.fit(train_dataset, epochs=1)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 816, in train_step\n>>>     self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 530, in minimize\n>>>     grads_and_vars = self._compute_gradients(\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 583, in _compute_gradients\n>>>     grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 464, in _get_gradients\n>>>     grads = tape.gradient(loss, var_list, grad_loss)\n>>> \n\nFunction call stack:\ntrain_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 58\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     59\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     61\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[200,1000,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/model/recur_a/transpose/transpose\n (defined at C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:464)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[gradient_tape/model/recur_a/RaggedToTensor/strided_slice/_180]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[200,1000,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/model/recur_a/transpose/transpose\n (defined at C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:464)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_9422]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/model/recur_a/transpose/transpose:\nIn[0] gradient_tape/model/recur_a/TensorArrayUnstack/TensorListStack:\t\nIn[1] gradient_tape/model/recur_a/transpose/InvertPermutation:\n\nOperation defined at: (most recent call last)\n>>>   File \"c:\\program files\\python38\\lib\\runpy.py\", line 193, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"c:\\program files\\python38\\lib\\runpy.py\", line 86, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"c:\\program files\\python38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"c:\\program files\\python38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"c:\\program files\\python38\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 461, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 450, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 652, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n>>>     if await self.run_code(code, result, async_=asy):\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\AppData\\Local\\Temp\\ipykernel_10760\\1211049778.py\", line 1, in <module>\n>>>     model.fit(train_dataset, epochs=1)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 816, in train_step\n>>>     self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 530, in minimize\n>>>     grads_and_vars = self._compute_gradients(\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 583, in _compute_gradients\n>>>     grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 464, in _get_gradients\n>>>     grads = tape.gradient(loss, var_list, grad_loss)\n>>> \n\nInput Source operations connected to node gradient_tape/model/recur_a/transpose/transpose:\nIn[0] gradient_tape/model/recur_a/TensorArrayUnstack/TensorListStack:\t\nIn[1] gradient_tape/model/recur_a/transpose/InvertPermutation:\n\nOperation defined at: (most recent call last)\n>>>   File \"c:\\program files\\python38\\lib\\runpy.py\", line 193, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"c:\\program files\\python38\\lib\\runpy.py\", line 86, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"c:\\program files\\python38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"c:\\program files\\python38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"c:\\program files\\python38\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 461, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 450, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 652, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n>>>     if await self.run_code(code, result, async_=asy):\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\AppData\\Local\\Temp\\ipykernel_10760\\1211049778.py\", line 1, in <module>\n>>>     model.fit(train_dataset, epochs=1)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 816, in train_step\n>>>     self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 530, in minimize\n>>>     grads_and_vars = self._compute_gradients(\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 583, in _compute_gradients\n>>>     grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n>>> \n>>>   File \"C:\\Users\\Anshul Kharbanda\\Documents\\GitHub\\toxicitykaggle\\env\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 464, in _get_gradients\n>>>     grads = tape.gradient(loss, var_list, grad_loss)\n>>> \n\nFunction call stack:\ntrain_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
